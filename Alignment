{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRB4prIxFQvD",
        "outputId": "576f6a51-66e6-4fe9-c2af-c9e48f3ab400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1THkEoXiFGqC"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxVAiYThFGqE"
      },
      "outputs": [],
      "source": [
        "link ='https://www.youtube.com/watch?v=dT_aIJZ7Mxw'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgzjYcmBFGqE"
      },
      "outputs": [],
      "source": [
        "# object creation using YouTube\n",
        "# which was imported in the beginning \n",
        "try:   \n",
        "    yt = YouTube(link) \n",
        "except: \n",
        "    print(\"Connection Error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibA2bGLuFGqF",
        "outputId": "989d9c79-2425-4152-bb21-88e6688c7e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#for 1st video\n",
        "yt.streams.filter(file_extension='mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mj3iS5eFGqF"
      },
      "outputs": [],
      "source": [
        "stream = yt.streams.get_by_itag(139)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBbeebEZFGqG",
        "outputId": "5226ef68-9ab9-404c-d597-02788a767cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GoogleImagen.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "stream.download('',\"GoogleImagen.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXSgQWQJwX0",
        "outputId": "d72b3c51-6fc4-4354-e4b0-1244c0c889bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-cd7gwfi7\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-cd7gwfi7\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 20.5 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175218 sha256=300da794b3ca04eef96ad935b44532761c4af784488d2ba8375572f585134ee5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sw223jxm/wheels/16/15/89/1c7bb31bd0006793a95549d04785121a8a36daad9158e1e43a\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0 whisper-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 46.1 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 25.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"GoogleImagen.mp4\")\n",
        "print(result['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJwhMsOhJgQm",
        "outputId": "b36be170-d8d0-49d8-c604-3f3e962db1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 123MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " In this video, let's look at image and a new AI system from Google Brain. So what does image and image and text as an input and then generates images. For example, the text over here is a chrome plated duck with a golden beak arguing with an angry turtle in a forest. So this is the text given and this is the image generated. So how does this system work? So this system takes text as an input. There is a frozen text encoder which produces a text embedding. This text embedding is then fed into a series of image diffusion models. There is a first text to image diffusion model which generates an image. Then there is a super resolution diffusion model which is used for increasing the resolution. Then you have another super resolution diffusion model which gives you the final image. And each of these diffusion models takes the text embedding as the input along with the previous output of the previous stage. So for the text encoder over here, they use a T5-XXL encoder to encode the input text into embeddings. Then they have conditional diffusion model maps that text embedding into the various 64 into 64 image. Then there is a further super-convict text condition, super resolution diffusion model which can upsample the image. 64 image into the final image. And if you look at the photos over here which have been generated based on the captions, the photo quality and the photo realism is much high when compared to Dali. Here is another example which they show over here. You can click on a word and you can see what is the kind of image which has been generated. For example, a photo of a British short hair cat wearing a cowboy hat and a red shirt riding a bike on a beach. This is the kind of image you get. If you go to the other one, this is an oil painting of the same thing. For example, this is a Persian cat. This is the image which has been generated. If you click on Fuzzy Panta, for the panda, this is the kind of image which has been generated based on this highlighted text caption. This is playing a guitar, this is riding a bike, this is skate boarding on top of a mountain. This is an oil painting. If you go to photo, you see this photo quality which has been generated. This seems much better than Dali and they say that when they looked at the benchmarks over here, they have attained a new state of art score. Image fidelity score when compared to Dali or the other models on the cocoa dataset. This is quite interesting work and I am amazed at the pace at which AI is developing now with newer models being developed by these big, big research teams achieving newer, fascinating results. I hope you liked this video on Image and if you liked the video, please like share subscribe to the channel, see you in another video. Happy learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuomGewROpwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link2 = 'https://www.youtube.com/watch?v=Jmbid-9a5mk'\n",
        "  # object creation using YouTube\n",
        " # which was imported in the beginning \n",
        "try:   \n",
        "    yt2 = YouTube(link2)\n",
        "except: \n",
        "    print(\"Connection Error\")\n",
        " #for 2nd video\n",
        "yt2.streams.filter(file_extension='mp4')\n",
        "stream2 = yt2.streams.get_by_itag(139)\n",
        "stream2.download('',\"reactjsVsnextjs.mp4\")"
      ],
      "metadata": {
        "id": "EFtEStD6MGQZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed8c8bc5-ca29-496c-dc6e-c0857f11efe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/reactjsVsnextjs.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model2 = whisper.load_model(\"base\")\n",
        "result2 = model2.transcribe(\"reactjsVsnextjs.mp4\")\n",
        "print(result2['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNaHNkfQOh0h",
        "outputId": "6de2bd75-8ddf-4a35-9a92-d08112ed8083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello guys, this is Kochbun. I just want to very quickly show you a comparison of vanilla react versus next JS, which is a, I guess a react framework, if you like. So this is useful for people who don't really know what server side rendering versus client side rendering is. It's also good for people who have used React a little bit, but maybe not are not aware of next JS. And it's also kind of useful for people who aren't really familiar with what next JS is as well. So one of the first things right off the bat is I want to show you is this website here, I've made two identical websites. It's my portfolio website. You don't have to worry about that. It's just a slight change I made later on. But very quickly, so this is React, vanilla react, and then this is the next JS one. So if I right click and I go to view page source, you'll notice that initially this is kind of just a bunch of JavaScript gibberish. And if I right click on the next JS one, you're going to see HTML. So one of the bonuses of next JS is that it's good for SEO. So when these search engines crawl through a website, for example, if it crawls through this one, it's not going to get any data because it's just a JavaScript file. Whereas this one, the next JS one, it's better for SEO purposes because it can actually go through all this information and catalog it. So SEO is one of the reasons why some people consider using next JS. Another one, which I think is probably the main one. For me personally, this is kind of blew my mind in terms of when I actually first saw it. So I'll just show you the vanilla react one. So I'm on my homepage and I'm going to click into my projects. So that's loading and I took a little bit of time. But the reason why that was loading was because when I clicked on the projects one, it's actually going into the backend, going because I created an API with the Django REST framework, Django is backend. And so it's going into the backend. It's getting the data and it's bringing the data back into the front end, this, into this react application. And that was a little bit slow, but it can actually get much slower because well for one of the reasons is this is hosted on Heroku. Heroku is one of the main deployment platforms people use for Django. And one of the problems is when people aren't using it, using your website, I believe it's for an hour, it shuts off. So when you click on it again, it takes even loader because it has to load up the, the Heroku site and then it gets the data and it brings it forth. And that's why that took a bit of time to bring that in. But now let me show you about next JS. Why this is so cool is when I click on projects, boom, it loads instantly. And the reason why is because next JS uses what's known as server side rendering, whereas Vinanilla react to uses what's known as client side rendering. And basically the, the, the gist of it is when you're using next JS, once you're, once you've created your application, your, your webpage and you deploy it, when you use something called get static paths, it creates those paths, well, statically. So it creates it as if it's like a default HTML webpage. So there's no going into the backend and retrieving the data. Just boom, the information is there and it's ready and it's ready to be used. So for example, back on to Vinanilla react, I click on skills, it needs to load, you can see, it takes a bit of time to go back and forth. And especially if you're making like a portfolio page or something, you can't have people, possibly prospective employers looking at this, waiting, maybe five, maybe 10 seconds for everything to load up. They just won't be interested. Most people have like a two second memory. So it's useful to have something like this particularly for some kind of CV portfolio website. As you can see, boom, it just loads instantly, which is great. So that's it, that's it guys. It was just something I wanted to show because when I first seen this kind of hands on with like a side by side of, of next JS and react, it kind of blew my mind a little bit. Maybe some of you are like, well, yeah, I've experienced this before, but I hadn't. So if you're reasonably new to react, this might be something you should look into and consider, I thought it was very interesting. Alright guys, thanks very much.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFVFC_IHPOn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zwR28uSPOp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INg3P5wvPOto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIMLDEAgPPAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.youtube.com/watch?v=Jmbid-9a5mk"
      ],
      "metadata": {
        "id": "26Pqyq2S77Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "#import youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0chggaI8YUI",
        "outputId": "69a60701-c688-4a3a-d46f-ebf857f4a5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from youtube-transcript-api) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (2022.9.24)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi as yta"
      ],
      "metadata": {
        "id": "UB9CcVWz8Yi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = 'Jmbid-9a5mk'"
      ],
      "metadata": {
        "id": "Bkh98CnW77pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = yta.get_transcript(video_id)"
      ],
      "metadata": {
        "id": "2GRiZnse8HQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = ''\n",
        "for value in data:\n",
        "  for key,val in value.items():\n",
        "    if key == 'text':\n",
        "      transcript += val\n",
        "\n",
        "l = transcript.splitlines()\n",
        "final_transcript = \" \".join(l)   "
      ],
      "metadata": {
        "id": "aVmBC7-U8Pm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge19jUxh-2-D",
        "outputId": "f259d5f8-2d63-41db-a135-d7daad10aadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello guys this is kokobun i just wantto very quickly show youa comparison of vanilla react versusnext js which is ai guess a react framework if you like umso this is useful for people who don'treally know what server side renderingversus client-side rendering isit's also good for people who have usedreact a little bit but maybe not are notaware of next yesand it's also kind of useful for peoplewho aren't really familiar with whatnexus is as wellso um the one one of the first thingsright off the bat is i want to show youisthis this website here i've made twoidentical websites it's my uh portfoliowebsiteuh you don't have to worry about thatit's just a slight change i made lateronbut um very quickly so this is um reactvanilla react and then this is the nextjs oneso if i right click and i go to viewpage source you'll notice that initiallythis is kind of just a bunch ofjavascript gibberish and if i rightclick on the next js oneyou're going to see html so one of thebonuses of nexus is that it's good forseoso uh when when these um search enginescrawl through a website for example ifit crawls throughthis one it's not going to get any databecause it's just a javascriptfile whereas this one the next.js oneit's better for seo purposes because itcan actuallygo through all this this information andcatalog itso seo is one of the the reasons whysome people consider using next.jsanother one which i think is probablythe main one for me personally this isthis kind of uh blew my mind in terms ofwhen i actually first saw itso i'll just show you the the vanillareact one soi'm on my homepage and i'm going toclick into my projectsso that's loading and it took a littlebit of time but the reason why that wasloading was becausewhen i clicked on the projects one it'sactually going into the back endgoing um because i created an api withthe django rest framework django'sbackendand so it's going into the back end it'sgetting the data and it's bringing thedata backinto the front end this the in into thisreactapplication and uh that was a little bitslow but it can actually getmuch slower because well for one of thereasons is this is hosted on herokuheroku is one of the main deploymentplatforms people use for django and oneof the problemsis when people aren't using it uh usingyour website i believe it's for an hourit shuts off so when you click on itagain it takes even loader because ithas to load up the heroku siteand then it gets the data and it bringsit forthand that's why that took a bit of timeto bring that in but now let me show youabout next.js why this is so cool iswhen i click on projectsboom it loads instantly and the reasonwhy is because nextgs uses what's knownas server-side renderingwhereas vanilla react uses what's knownas client sound renderingand basically the the gist of itis when you're using next.js once you'reonce you've created yourapplication your your web page and youdeploy itwhen you use something called get staticpaths it creates those pathswell statically so it creates it as ifit's like a default html web pageso there's no going into the back endand retrieving the datait's just boom the information is thereand it's readyand it's ready to be used so for exampleback under vanilla react i click onskills it needs to loadyou can see takes a bit of time to goback and forth and especially if you'remaking like aportfolio page or something you can'thave peoplepossibly prospective employers lookingat this waitingmaybe five maybe 10 seconds foreverything to load up they just won't beinterested most people have like a twosecond memoryso it's useful to have something likethis particularly for some kind of umcv portfolio website as you can see boomit just loads instantlywhich is great um so that's it that's itguysum it was just something i wanted toshow because when i firstseen this kind of hands-on with like aside by side ofof next yes and react it kind of blew mymind a little bitmaybe some of you are like well yeahi've experienced this before buti hadn't so if you're reasonably new toreact this might be something you shouldlook into and considerum i thought it was very interesting allright guys thanks very much\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"file-one.txt\", \"w\")\n",
        "file.write(final_transcript)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "M4lotHOv-eqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "dataset = [[\"Title\", \"Text\"],\n",
        "             [\"GoogleImagen\", result],\n",
        "             [\"reactjsVsnextjs\", result2],\n",
        "             [\"GoogleImagen\", result],\n",
        "            [\"reactjsVsnextjs\", result2]\n",
        "            ]\n",
        "\n",
        "with open('/content/csv-text.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(dataset)"
      ],
      "metadata": {
        "id": "XSdn7K38WS2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "rVjGXqeSbPow",
        "outputId": "6d449167-88d1-4264-e558-4fade11143f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 27.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=f11d5542e6537efd33ba159cc40d4aae6735297ef7e0ab3f8b337d393600455c\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/de/db/e82770b480ec30fd4a6d67108744b9c52be167c04fcf4af7b5\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.2.0.62\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai, numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Yrwf3G1hXrJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('../content/csv-text.csv')\n",
        "#dataset['Text'] = df['Text'].str.replace('\\n', '')\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "LDa6cOU9XwvW",
        "outputId": "fe13936e-ee80-4d7e-f358-30e737c0e742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Title                                               Text\n",
              "0     GoogleImagen  {'text': \" In this video, let's look at image ...\n",
              "1  reactjsVsnextjs  {'text': \" Hello guys, this is Kochbun. I just...\n",
              "2     GoogleImagen  {'text': \" In this video, let's look at image ...\n",
              "3  reactjsVsnextjs  {'text': \" Hello guys, this is Kochbun. I just..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28e15a3c-f738-4669-9986-8ce5333a9b49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GoogleImagen</td>\n",
              "      <td>{'text': \" In this video, let's look at image ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reactjsVsnextjs</td>\n",
              "      <td>{'text': \" Hello guys, this is Kochbun. I just...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GoogleImagen</td>\n",
              "      <td>{'text': \" In this video, let's look at image ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>reactjsVsnextjs</td>\n",
              "      <td>{'text': \" Hello guys, this is Kochbun. I just...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28e15a3c-f738-4669-9986-8ce5333a9b49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28e15a3c-f738-4669-9986-8ce5333a9b49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28e15a3c-f738-4669-9986-8ce5333a9b49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import nltk\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import regex as re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "7ftM3ic_YDEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-zT8H_SfNJW",
        "outputId": "960a8806-60d2-474a-d8bd-2f3a588d08a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxQVq43HfpVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# components for features reduction\n",
        "n_components = 5\n",
        "# number of clusters we want\n",
        "n_clusters = 4\n",
        "\n",
        "# covert words into TFIDF metrics\n",
        "tfidf = TfidfVectorizer(stop_words = 'english')\n",
        "X_text = tfidf.fit_transform(dataset['Text'])\n",
        "\n",
        "# reduce dimensions\n",
        "svd = TruncatedSVD(n_components=n_components, random_state = 0)\n",
        "X_2d = svd.fit_transform(X_text)\n",
        "\n",
        "# fit k-mean clustering\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state = 0)\n",
        "\n",
        "# predict our clusters for each video text\n",
        "X_clustered = kmeans.fit_predict(X_2d)\n",
        "# display by groups\n",
        "df_plot = pd.DataFrame(list(X_2d), list(X_clustered))\n",
        "df_plot = df_plot.reset_index()\n",
        "df_plot.rename(columns = {'index': 'Cluster'}, inplace = True)\n",
        "df_plot['Cluster'] = df_plot['Cluster'].astype(int)\n",
        "\n",
        "print(df_plot.head())\n",
        "\n",
        "print(df_plot.groupby('Cluster').agg({'Cluster': 'count'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U15fBS7aY3C0",
        "outputId": "cd4e6e17-69dd-4797-e4b5-4864dbc2ebac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cluster         0         1             2             3\n",
            "0        0  0.868754 -0.495244 -2.412350e-18 -1.192622e-17\n",
            "1        1  0.868754  0.495244 -1.043138e-16  1.266619e-16\n",
            "2        0  0.868754 -0.495244 -2.412350e-18 -1.192622e-17\n",
            "3        1  0.868754  0.495244 -1.043138e-16  1.266619e-16\n",
            "         Cluster\n",
            "Cluster         \n",
            "0              2\n",
            "1              2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1255: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA\n",
        "no_topics = 5\n",
        "\n",
        "c = CountVectorizer(stop_words='english')\n",
        "X_text_c = c.fit_transform(dataset['Text'])\n",
        "\n",
        "lda = LatentDirichletAllocation(learning_method = 'online', n_components=no_topics, random_state=0).fit(X_text_c)\n",
        "X_text_c_feature_names = c.get_feature_names()\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print (\"Topic %d:\" % (topic_idx))\n",
        "        print (\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "no_top_words = 10\n",
        "display_topics(lda, X_text_c_feature_names, no_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXh_llE2Y3GP",
        "outputId": "060f17ed-cce9-4ab1-8176-26a492ea5046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "13 264 11 307 295 293 257 286 341 281\n",
            "Topic 1:\n",
            "11 13 264 257 307 309 293 311 286 341\n",
            "Topic 2:\n",
            "11 13 309 264 307 295 311 286 291 341\n",
            "Topic 3:\n",
            "13 264 257 307 11 3256 341 text 2487 597\n",
            "Topic 4:\n",
            "11 13 309 264 307 311 286 295 291 281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key='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'\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "aEf3JBmZgzM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enter the json filename to be converted to json\n",
        "#JSON_FILE = 'json_file.json'\n",
        "\n",
        "# enter the csv filename you wish to save it as\n",
        "#CSV_FILE = '/content/csv-text.csv'\n",
        "\n",
        "#with open(JSON_FILE, encoding = 'utf-8') as f :\n",
        "#\tdf = pd.read_json(f)\n",
        "    \n",
        "#df.to_csv(CSV_FILE, encoding = 'utf-8', index = False)"
      ],
      "metadata": {
        "id": "a0fc2Ja0hRhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fl6Gco4mbyHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec=TfidfVectorizer(stop_words=\"english\", ngram_range = (1,3))\n",
        "vec.fit(dataset.Text.values)\n",
        "features = vec.transform(dataset.Text.values)"
      ],
      "metadata": {
        "id": "edM6zq-RlQYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "clust=KMeans(init='k-means++', n_clusters=2, n_init=10)\n",
        "clust.fit (features)"
      ],
      "metadata": {
        "id": "68Yzn2e2lQcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Cluster Labels']=clust.labels_\n",
        "dataset"
      ],
      "metadata": {
        "id": "oK5lWffTlQhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1=dataset.loc[dataset['Cluster Labels']==1]\n",
        "df_1"
      ],
      "metadata": {
        "id": "7zf-yDRrlQk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2=dataset.loc[dataset['Cluster Labels']==0]\n",
        "df_2"
      ],
      "metadata": {
        "id": "QNyfZ2M4nnBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_sim=cosine_similarity(features)"
      ],
      "metadata": {
        "id": "BUjGGoTpoivq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def getind (c):\n",
        "  #return dataset[dataset.Text==c].index.tolist()"
      ],
      "metadata": {
        "id": "Ds_ytQT1ooDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def getscene(i):\n",
        "  #return dataset[dataset.index==i].Text.tolist()"
      ],
      "metadata": {
        "id": "yzG-hw7Mo-dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#similar=list(enumerate(cosine_sim[i]))\n",
        "#similar"
      ],
      "metadata": {
        "id": "fq757GEAo-hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''similar_list=[]\n",
        "disimilar_list=[]\n",
        "for m in sortsim:\n",
        "tgetscene (m[ 0] )\n",
        "if m[l ]>0.15:\n",
        "similar_1ist . append (t)\n",
        "else:\n",
        "disimilar_list.append (t)\n",
        "df_similar-pd.DataFr ame ( similar_list,, columns=[ \"Scenarios \" ] )\n",
        "df_disimilar=pd.DataFrame (disimilar_list, columns=[ \"Scenarios\"])'''"
      ],
      "metadata": {
        "id": "lyF_rmwjqB3d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}